--- 

layout: post
title:  "Ինչ է prompt-ը, դրա տեսակները"
image:  assets/images/1.jpg
author: Monica
---

**Ինչ է Prompt-ը** <br/>
Prompt-ը LLM-ին  ուղղված հրահանգ է։Օրինակ ChatGPT-ի հետ շբվելիս օգտագործում ենք prompt-ներ (հուշումներ):Ճշգրիտ հուշումը  վերադարձնում է համապատասխան ձևով և բովանդակությամբ պատասխան։Օրինակներ․<br/>
1․Ասա մի անեկդոտ [ձեր թեման] մասին։<br/>
2․Գրեք ինձ պաշտոնական բողոք [կազմակարպության անունը] հասցեին՝ [ապրանքի անուն]-ի օգտագործման իմ փորձի վերաբերյալ:<br/>
3․Կազմիր շաբաթվա ուտելիքների գրաֆիկ,որոնք կարող եմ պատրաստել հետևյալ ապրանքներով  [թվարկեք ապրանքները]։<br/>
4․ Գործիր որպես թարգմանիչ: Ես կներկայացնեմ մի տեքստ անգլերենով, և ես կցանկանայի, որ այն թարգմանեք հայերեն և ուղղեք ուղղագրական և քերականական սխալները։ <br/>
5․ Խնդրում եմ վերանայել իմ CV-ն և առաջարկել այնպիսի խմբագրումներ, որոնք ինձ ավելի գրավիչ են դարձնում [պաշտոնի անուն] դերի համար: Ձեզ եմ ներկայացնում իմ հմտությունների և փորձի ցանկը:<br/>

**Prompt engineering hacks**<br/>
LLM-ների հետազոտողները և user-ները հայտնաբերել են որոշ հնարքներ, որոնք բարելավում են մոդելների պատասխանները։ Ահա մի քանի խորհուրդ.<br/>
1․ Ասա՜ <<արա>>, մի ասա <<մի արա>>։<br/>
2․ Ուշադրություն դարձրեք  prompt-ների երկարություններին,շատ երկար պետք չէ որ լինի ։<br/>
3․Եղեք կոնկրետ։<br/>
4․Կառուցեք հուշումը իմաստալից կերպով։<br/>
5․ Բառերը ընտրեք մտածված(մի օգտագործեք երկիմաստ,ժարգոնային բառեր, փոխաբերություններ)։<br/>

**Ինչ է  Prompt hacking-ը**<br/>
Prompt hacking-ը տերմին է որը օգտագործվում է նկարագրելու հարձակման մի տեսակ, որն օգտագործվում է  LLM-ների խոցելիությունը՝ շահարկելով նրանց մուտքերը(inputs) կամ  հուշումները(prompts)։Ի տարբերություն ավանդական հաքերային հարձակման, որը սովորաբար օգտագործում է ծրագրային ապահովման խոցելիությունը, prompt hacking-ը հիմնված է զգուշորեն մշակված հուծումների վրա՝ LLM-ներին չնախատեսված գործողություններ կատարել դրդելու համար։
Կան prompt hacking-ի 3 տեսակներ՝ *Prompt injection,Prompt leaking և Jailbreaking*:<br/>
**Prompt injection**-ը ներառում է վնասակար կամ չնախատեսված բովանդակության ավելացում՝ լեզվական մոդելի output-ներից “առևանգելու” անհրաժեշտ տեղեկատվություն։
![Injection example ](../assets/images/haching.png)<br/>

**Prompt leaking**-ը  LLM-ի  output-ներից զգայուն կամ գաղտնի ինֆորմացիայի դուրսբերումն է։
![Leaking example ](../assets/images/leaking.png)

**Jailbreaking**-ը արտադրողի կողմից սահմանված սահմանափակումների փոփոխումն է,ներառում է անվտանգության չափանիշների շրջանցում,օրինակ՝ թույլ տալ չթույլատրված ծրագրակազմի տեղադրումը։
![Jailberaking example ](../assets/images/jailbreaking.png)

Prompt hacking-ից պաշտպանվելու համար պետք է պաշտմանական միջոցներ ձեռնարկվեն,որոնք ներառում են հատուկ պաշտպանական տեխնիկայի կիրառում,  LLM-ի վարքագծի և output-ների կանոնավոր մոնիթորինգ` հայտնաբերելու համար անսովոր գործունեությունը։


